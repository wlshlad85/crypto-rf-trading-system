name: CI - GPU/CPU Regression Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      update_baseline:
        description: 'Update baseline expectations'
        required: false
        default: 'false'

jobs:
  # CPU tests run on GitHub-hosted runners
  test-cpu:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install CPU dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Generate golden dataset
      run: |
        python scripts/generate_golden_data.py
        ls -la tests/data/
    
    - name: Run CPU tests
      run: |
        pytest tests/test_regression.py -v -k "cpu"
        pytest tests/test_latency.py::TestLatencyBudget::test_cpu_latency -v
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results-cpu-${{ matrix.python-version }}
        path: |
          tests/data/golden.parquet.stats.json
          pytest_results.xml
        retention-days: 7

  # GPU tests run on self-hosted runner
  test-gpu:
    runs-on: [self-hosted, gpu]
    strategy:
      matrix:
        python-version: ["3.10"]
        cuda-version: ["11.8", "12.1"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      run: |
        # Assumes conda/mamba is available on self-hosted runner
        conda create -n test-env python=${{ matrix.python-version }} -y || true
        conda activate test-env
    
    - name: Install GPU dependencies
      run: |
        # Activate the conda environment
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate test-env
        
        # Install CUDA-specific packages
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-gpu-cuda${{ matrix.cuda-version }}.txt
        pip install -r requirements-test.txt
        
        # Verify GPU is available
        python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
        python -c "import cupy; print(f'CuPy version: {cupy.__version__}')"
        nvidia-smi
    
    - name: Generate golden dataset
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate test-env
        python scripts/generate_golden_data.py
    
    - name: Run GPU tests
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate test-env
        
        # Full test suite
        pytest tests/test_regression.py -v
        pytest tests/test_latency.py -v
        
        # Save performance results
        python scripts/run_pipeline.py --mode gpu --input tests/data/golden.parquet --out gpu_results.json
    
    - name: Check GPU speedup
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate test-env
        
        # Compare CPU vs GPU performance
        python scripts/run_pipeline.py --mode cpu --input tests/data/golden.parquet --out cpu_results.json
        python -c "
import json
with open('cpu_results.json') as f: cpu = json.load(f)
with open('gpu_results.json') as f: gpu = json.load(f)
speedup = cpu['execution_time_ms'] / gpu['execution_time_ms']
print(f'GPU Speedup: {speedup:.2f}x')
print(f'CPU: {cpu[\"execution_time_ms\"]:.1f}ms')
print(f'GPU: {gpu[\"execution_time_ms\"]:.1f}ms')
assert speedup >= 3.0, f'GPU speedup too low: {speedup:.2f}x'
        "
    
    - name: Upload GPU results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results-gpu-cuda${{ matrix.cuda-version }}
        path: |
          *_results.json
          pytest_results.xml
        retention-days: 7
    
    - name: Cleanup conda environment
      if: always()
      run: |
        conda remove -n test-env --all -y || true

  # Baseline update job (manual trigger only)
  update-baseline:
    if: github.event.inputs.update_baseline == 'true'
    runs-on: [self-hosted, gpu]
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      run: |
        conda create -n baseline-env python=3.10 -y || true
        conda activate baseline-env
    
    - name: Install dependencies
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate baseline-env
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-gpu-cuda11.8.txt
        pip install -r requirements-test.txt
    
    - name: Update baseline
      run: |
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate baseline-env
        
        # Run baseline update script
        python scripts/update_baseline.py
        
        # Verify new expectations
        pytest tests/test_regression.py -v
    
    - name: Commit updated baseline
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add tests/expectations.yaml
        git diff --staged --quiet || git commit -m "Update baseline expectations [skip ci]"
        git push
    
    - name: Cleanup
      if: always()
      run: |
        conda remove -n baseline-env --all -y || true

  # Summary job
  test-summary:
    needs: [test-cpu, test-gpu]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate summary report
      run: |
        echo "## Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check CPU results
        echo "### CPU Tests" >> $GITHUB_STEP_SUMMARY
        for dir in test-results-cpu-*; do
          if [ -d "$dir" ]; then
            echo "- $dir: ✅" >> $GITHUB_STEP_SUMMARY
          fi
        done
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check GPU results
        echo "### GPU Tests" >> $GITHUB_STEP_SUMMARY
        for dir in test-results-gpu-*; do
          if [ -d "$dir" ]; then
            echo "- $dir: ✅" >> $GITHUB_STEP_SUMMARY
            if [ -f "$dir/gpu_results.json" ] && [ -f "$dir/cpu_results.json" ]; then
              python3 -c "
import json
with open('$dir/cpu_results.json') as f: cpu = json.load(f)
with open('$dir/gpu_results.json') as f: gpu = json.load(f)
speedup = cpu['execution_time_ms'] / gpu['execution_time_ms']
print(f'  - Speedup: {speedup:.2f}x')
print(f'  - CPU: {cpu[\"execution_time_ms\"]:.1f}ms')
print(f'  - GPU: {gpu[\"execution_time_ms\"]:.1f}ms')
              " >> $GITHUB_STEP_SUMMARY
            fi
          fi
        done