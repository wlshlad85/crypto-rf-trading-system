#!/usr/bin/env python3
"""
Test Meta-Optimizer Layer Components

Quick verification that all meta-optimizer components are working correctly.
"""

import sys
import os
import traceback

# Add path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_objective_function():
    """Test the objective function."""
    print("ğŸ¯ Testing Meta-Objective Function...")
    
    try:
        from meta_optim.objective_fn import MetaObjectiveFunction
        
        # Create sample data
        sample_results = {
            'trades': [
                {'action': 'BUY', 'value': 1000, 'pnl': 0},
                {'action': 'SELL', 'value': 1100, 'pnl': 100},
                {'action': 'BUY', 'value': 1100, 'pnl': 0},
                {'action': 'SELL', 'value': 1200, 'pnl': 100}
            ],
            'portfolio_values': [100000] + [100000 + i*100 for i in range(1, 21)]
        }
        
        objective_fn = MetaObjectiveFunction()
        results = objective_fn.evaluate_strategy(sample_results)
        
        print(f"  âœ… Composite Score: {results['composite_score']:.3f}")
        print(f"  âœ… Strategy Viable: {results['viable']}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        traceback.print_exc()
        return False

def test_retrain_worker():
    """Test the retrain worker."""
    print("ğŸ”„ Testing Retrain Worker...")
    
    try:
        from meta_optim.retrain_worker import RetrainWorker
        
        # Test configuration
        test_config = {
            'entry_model': {
                'n_estimators': 50,
                'max_depth': 8,
                'min_samples_split': 10,
                'min_samples_leaf': 5
            },
            'trading_params': {
                'momentum_threshold': 1.78,
                'position_range_min': 0.464,
                'position_range_max': 0.800,
                'confidence_threshold': 0.6,
                'exit_threshold': 0.5
            }
        }
        
        worker = RetrainWorker()
        results = worker.train_and_evaluate(test_config, training_fraction=0.1)
        
        print(f"  âœ… Training completed")
        print(f"  âœ… Final Value: ${results.get('final_value', 0):,.2f}")
        print(f"  âœ… Total Trades: {results.get('num_trades', 0)}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        traceback.print_exc()
        return False

def test_hyperband_runner():
    """Test the hyperband runner (minimal test)."""
    print("ğŸ¯ Testing Hyperband Runner...")
    
    try:
        from meta_optim.hyperband_runner import HyperbandRunner
        
        runner = HyperbandRunner()
        
        # Test configuration sampling
        configs = runner._sample_configurations(2)
        
        print(f"  âœ… Generated {len(configs)} test configurations")
        print(f"  âœ… Parameter space loaded successfully")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        traceback.print_exc()
        return False

def test_deployment_cycle():
    """Test the deployment cycle (initialization only)."""
    print("ğŸš€ Testing Deployment Cycle...")
    
    try:
        from meta_optim.deployment_cycle import MetaDeploymentCycle
        
        cycle = MetaDeploymentCycle()
        
        print(f"  âœ… Deployment cycle initialized")
        print(f"  âœ… Configuration loaded")
        print(f"  âœ… Components ready")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        traceback.print_exc()
        return False

def main():
    """Run all tests."""
    print("ğŸ§ª META-OPTIMIZER LAYER TESTS")
    print("=" * 50)
    
    tests = [
        ("Objective Function", test_objective_function),
        ("Retrain Worker", test_retrain_worker),
        ("Hyperband Runner", test_hyperband_runner),
        ("Deployment Cycle", test_deployment_cycle)
    ]
    
    results = []
    
    for name, test_func in tests:
        print(f"\nğŸ” Testing {name}...")
        success = test_func()
        results.append((name, success))
        print()
    
    # Summary
    print("=" * 50)
    print("ğŸ TEST SUMMARY")
    print("=" * 50)
    
    passed = 0
    for name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{name}: {status}")
        if success:
            passed += 1
    
    print(f"\nTotal: {passed}/{len(results)} tests passed")
    
    if passed == len(results):
        print("\nğŸ‰ All meta-optimizer components are working correctly!")
        print("ğŸš€ Ready for production deployment!")
    else:
        print(f"\nâš ï¸ {len(results) - passed} tests failed - review errors above")

if __name__ == "__main__":
    main()